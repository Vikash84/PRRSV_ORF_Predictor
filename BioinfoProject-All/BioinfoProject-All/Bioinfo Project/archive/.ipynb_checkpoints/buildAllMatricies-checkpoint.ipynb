{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'inputGenomes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8378bcb0f0db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mflatfiles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"inputGenomes\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mflatfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'inputGenomes'"
     ]
    }
   ],
   "source": [
    "#imports and reading in files + path setup\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "flatfiles=[]\n",
    "for filename in os.listdir(\"inputGenomes\"):\n",
    "    flatfiles.append(filename)\n",
    "\n",
    "path='C:\\\\Users\\\\Matt\\\\Desktop\\\\Bioinfo Project\\\\inputGenomes\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseFile(filename, path):\n",
    "    fileString=open(path+filename).read()\n",
    "    #AQUIRE START INDICIES\n",
    "    #CDS tag marks open reading frame annotation\n",
    "    startIndex=fileString.find(\"CDS \")\n",
    "    #arrays for storing annotated genome ORF starts and ends \n",
    "    starts=[]\n",
    "    ends=[]\n",
    "    #loop to find all annotated ORFs\n",
    "    while startIndex>0:\n",
    "        #only search short segement of file after CDS tag\n",
    "        temp=fileString[startIndex:startIndex+50]\n",
    "        #regualar expression to find start index\n",
    "        startEx=r'[ join(]\\d+'\n",
    "        #regualar expression to find end index\n",
    "        endEx=r'\\.\\.\\d+'\n",
    "        #print(temp.replace(\" \",\"\")[3])\n",
    "        try:\n",
    "            starts.append(int(re.search(startEx,temp).group(0)[1:]))\n",
    "        except:\n",
    "            if not temp.replace(\" \",\"\")[3]=='<':\n",
    "                print(filename)\n",
    "        #move to next CDS tag --is set to -1 if no more CDS tags are found, ending the loop\n",
    "        startIndex=fileString.find(\"CDS \",startIndex+1)\n",
    "    \n",
    "    #ISOLATE GENOME\n",
    "    genome=fileString[fileString.find(\"ORIGIN\")+6:len(fileString)]\n",
    "    genome=re.sub(r'[^a-z]+',\"\",genome)\n",
    "    \n",
    "    #CHANGE T BASE TO U TO REPRESENT AS RNA\n",
    "    genomeRNA=genome.replace(\"t\",\"u\")\n",
    "    \n",
    "    #Get all start codons in genome\n",
    "    startCodonIndicies=[]\n",
    "    for i in range(len(genomeRNA)):\n",
    "        if genomeRNA[i:i+3]=='aug':\n",
    "            startCodonIndicies.append(i+1)\n",
    "    \n",
    "    #only add start codon to false starts if it is not in the true starts array\n",
    "    falsePositiveStarts=[]\n",
    "    for index in startCodonIndicies:\n",
    "        if index in starts:\n",
    "            pass\n",
    "        else:\n",
    "            falsePositiveStarts.append(index)\n",
    "    trueStarts=[]\n",
    "    for i in range(len(starts)):\n",
    "        #seperate orf1 start from all other true starts\n",
    "        if i==0:\n",
    "            index=starts[i]\n",
    "            orf1Start=genomeRNA[index-11:index+14]\n",
    "        else:\n",
    "            index=starts[i]\n",
    "            code=genomeRNA[index-11:index+14]+filename\n",
    "            trueStarts.append(genomeRNA[index-11:index+14]+filename+ \" \" + str(index))\n",
    "    falseStarts=[]\n",
    "    for index in falsePositiveStarts:\n",
    "        falseStarts.append(genomeRNA[index-11:index+14]+filename+ \" \" + str(index))\n",
    "    return {\"trueStarts\": trueStarts, \"falseStarts\": falseStarts, \"orf1Start\": orf1Start}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildSpaces():\n",
    "    trueStartSpace=[]\n",
    "    falseStartSpace=[]\n",
    "    orf1StartSpace=[]\n",
    "    #iterate through all flat files and parse them into start codon spaces\n",
    "    for i in range(len(flatfiles)):\n",
    "        space=parseFile(flatfiles[i],path)\n",
    "        trueStartSpace+=space[\"trueStarts\"]\n",
    "        falseStartSpace+=space[\"falseStarts\"]\n",
    "        orf1StartSpace.append(space[\"orf1Start\"])\n",
    "    return {\"trueStartSpace\": trueStartSpace, \"falseStartSpace\": falseStartSpace, \"orf1StartSpace\": orf1StartSpace}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildScoringMatrix(startSpace, numNucs):\n",
    "    #dictionary of positions and their corrosponding nucleotide values\n",
    "    startIdentities={\"A\": [0 for i in range(numNucs)], \"U\": [0 for i in range(numNucs)], \"G\": [0 for i in range(numNucs)], \"C\": [0 for i in range(numNucs)]}\n",
    "    #for each sequence in orf1 start sequences add nucleoides at each position to matrix\n",
    "    for i in startSpace:\n",
    "        seq=i.upper()\n",
    "        for n in range(numNucs):\n",
    "            try:\n",
    "                startIdentities[seq[n]][n]+=1\n",
    "            except:\n",
    "                #prints exception if a sequence of invalid length is used\n",
    "                print(\"except: \" + seq)\n",
    "    #store as dataframe for formatting\n",
    "    startIDsDF=pd.DataFrame.from_dict(startIdentities)\n",
    "    #print(startIDsDF.T)\n",
    "    \n",
    "    #turn identities matrix into frequency matrix\n",
    "    for key in startIdentities:\n",
    "        for i in range(numNucs):\n",
    "            startIdentities[key][i]=round(startIdentities[key][i]/len(startSpace),2)\n",
    "    startFreqsDF=pd.DataFrame.from_dict(startIdentities)\n",
    "    #print(startFreqsDF.T)\n",
    "    return(startFreqsDF)\n",
    "    with open(\"outt.txt\") as f:\n",
    "        f.write(startFreqsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreSequence(seq, matrix):\n",
    "    positions=[0,1,2,3,4,5,6,7,8,9,13,14,15,16,17,18,19,20,21,22,23,24]\n",
    "    weights=[3,3,1,0,1,1,4,4,2,3,0,0,0,1,1,2,2,2,4,2,1,1,2,2,2]\n",
    "    seq=seq.upper()\n",
    "    score=1\n",
    "    for i in positions:\n",
    "        try:\n",
    "            positionScore=matrix[seq[i]][i]\n",
    "        except:\n",
    "            positionScore=0\n",
    "        #for m in range(weights[i]):\n",
    "        #    positionScore*=positionScore\n",
    "        if positionScore==0:\n",
    "            score*=.000001\n",
    "        else:\n",
    "            score*=positionScore\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to help evaluate threshold scores\n",
    "def getAllScores(trueSpace, falseSpace, matrix):\n",
    "    trueHigh=0\n",
    "    trueLow=999\n",
    "    trueAVG=0\n",
    "    falseHigh=0\n",
    "    falseLow=999\n",
    "    falseAVG=0\n",
    "    \n",
    "    #false start scores\n",
    "    for i in range(len(falseSpace)):\n",
    "        s=scoreSequence(falseSpace[i],matrix)\n",
    "        #if s>.39: print(falseStartSpace[i] + str(s))\n",
    "        if s>falseHigh: falseHigh=s\n",
    "        if s<falseLow: falseLow=s\n",
    "        falseAVG+=s\n",
    "        #print(s)\n",
    "    falseAVG/=len(falseSpace)\n",
    "    #true start scores\n",
    "    for i in range(len(trueSpace)):\n",
    "        s=scoreSequence(trueSpace[i],matrix)\n",
    "        #if s<falseHigh: print(trueSpace[i] + str(s))\n",
    "        if s>trueHigh: trueHigh=s\n",
    "        if s<trueLow: trueLow=s\n",
    "        trueAVG+=s\n",
    "        #print(s)\n",
    "    trueAVG/=len(trueSpace)\n",
    "    return {\"True High\": trueHigh, \"True Low\": trueLow, \"True AVG\": trueAVG, \"False High\": falseHigh, \"False Low\": falseLow, \"False AVG\": falseAVG}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build scoring matricies and save to pickle for fast load & use in annotation script\n",
    "spaces=buildSpaces()\n",
    "print(\"spaces built\")\n",
    "orf1matrix=buildScoringMatrix(spaces[\"orf1StartSpace\"], 25)\n",
    "orf1matrix.to_pickle(\"loadData\\\\orf1matrix.pckl\")\n",
    "allORFmatrix=buildScoringMatrix(spaces[\"trueStartSpace\"], 25)\n",
    "allORFmatrix.to_pickle(\"loadData\\\\allORFmatrix.pckl\")\n",
    "print(\"matrices built\")\n",
    "\n",
    "#determine score threshold values\n",
    "orf1Scores=getAllScores(spaces[\"orf1StartSpace\"], spaces[\"falseStartSpace\"], orf1matrix)\n",
    "orf1Threshold=(orf1Scores[\"True Low\"]+orf1Scores[\"False High\"])/2\n",
    "print(orf1Scores)\n",
    "allORFScores=getAllScores(spaces[\"trueStartSpace\"], spaces[\"falseStartSpace\"], allORFmatrix)\n",
    "print(allORFScores)\n",
    "allORFThreshold=allORFScores[\"True Low\"]\n",
    "with open(\"loadData\\\\thresholdScores.txt\",'w') as f:\n",
    "    f.write(str(orf1Threshold)+\"\\n\")\n",
    "    f.write(str(allORFThreshold)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(allORFmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
